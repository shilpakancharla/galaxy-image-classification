# -*- coding: utf-8 -*-
"""SVM_and_RF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13de1oqnXbaMgAqmNIdItW4q69PfvDVeO
"""

# mounting on Google Drive,below 2 lines helps in getting the authorization code by loggin into your Google account
from google.colab import drive
drive.mount('/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# Importing all the required libraries
import os
import matplotlib as mpl 
import matplotlib.pyplot as plt
from IPython.display import display
# %matplotlib inline

import pandas as pd
import numpy as np
import pickle
from PIL import Image

from skimage.feature import hog
from skimage.color import rgb2grey
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from itertools import cycle 
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve, auc

# Import PCA datastet
PCA_PATH = "/gdrive/Shareddrives/ALDA_Project/data/pca_dataset/PCs.npy"
LABELS_PATH = "/gdrive/Shareddrives/ALDA_Project/data/pca_dataset/labels.npy"
Img_PATH = "/gdrive/Shareddrives/ALDA_Project/data/pca_dataset/images.npy"
# X as it has dataset containing PC's per image
pcs = np.load(PCA_PATH) 
# Y as it has labels for particular image
labels = np.load(LABELS_PATH) 
images = np.load(Img_PATH) 

CLASS_NAMES = ["elliptical", "spiral", "irregular", "invalid"]

print("Image", images[1])

# Displaying PCs and labels for reference
print("PCs", pcs)
print("Labels", labels)

# Using dataframes to store X and Y values
X = pd.DataFrame(pcs)
y = pd.Series(labels)
# splitting the data set into X_train,X_test, y_train, y_test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)
# Looking at distribution of labels in the training set
pd.Series(y_train).value_counts()
#type(y_train)

# Applying SVM on X_train, y_train data 
svm = SVC(kernel='linear', probability=True, random_state=42)
svm.fit(X_train, y_train)
# predicting the test dataset values 
y_pred = svm.predict(X_test)
# printing classification report which has precision,recall,accuraccy...etc
print(classification_report(y_test, y_pred, digits=8))

filename ="/gdrive/Shareddrives/ALDA_Project/data/svm_model.sav"
#model = SVC(kernel='linear', probability=True, random_state=42)
#model.fit(X_train, y_train)
pickle.dump(svm, open(filename, 'wb'))
 
# some time later...
 
# load the model from disk
loaded_model = pickle.load(open(filename, 'rb'))
model_pred = loaded_model.predict(X_test)
print(classification_report(y_test, model_pred, digits=8))
#result = loaded_model.score(X_test, Y_test)

#Applying Random Forest classifier on our dataset with number of trees in the forest to be 100
regressor = RandomForestClassifier(n_estimators = 100, random_state = 0)
regressor.fit(X_train, y_train)
# predicting the test dataset values 
y_pred = regressor.predict(X_test)
#preview of Actual and Predicted values from Random Forest classification
df=pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})
print(df)
# printing classification report which has precision,recall,accuraccy...etc
print(classification_report(y_test, y_pred, digits=8))

filename ="/gdrive/Shareddrives/ALDA_Project/data/Final_models/rf_model.sav"
#model = SVC(kernel='linear', probability=True, random_state=42)
#model.fit(X_train, y_train)
pickle.dump(regressor, open(filename, 'wb'))
 
# some time later...
 
# load the model from disk
loaded_model = pickle.load(open(filename, 'rb'))
model_pred = loaded_model.predict(X_test)
print(classification_report(y_pred, model_pred, digits=8))



import random
# sample images
cols = 3
rows = 3
NO_INDICES = df.shape[0]
plt.figure(figsize=(cols*5, rows*5))
for i in range(rows):
  for j in range(cols):
    ax = plt.subplot(rows, cols, i*cols + j+1)
    indx = random.choice(df.index)

    gt = df.Actual[indx]
    pred = df.Predicted[indx]
    title_string = "GT:" + str(CLASS_NAMES[gt]) + "\nPRED:" + str(CLASS_NAMES[pred])

    ax.set_xticks([])
    ax.set_yticks([])
    
    ax.set_title(title_string, fontdict={"fontsize": 20})
    ax.imshow(images[indx])



# plt.imshow(images[2647])
# print("Actual=", df.Actual[2647])
# print("Prediction=" ,df.Predicted[2647])

# sample images
cols = 3
rows = 3

row_images = []

for i in range(rows):
  indices = np.random.rand(cols)
  indices = (indices*NUMBER_IMAGES).astype(np.int64)  

  row = images[indices[0], ...]
  for j in range(1, cols):
    row = np.hstack((row, images[indices[j]]))
  
  row_images.append(row[:])

image = row_images[0]
for i in range(1, rows):
  image = np.vstack((image, row_images[i]))

plt.figure(figsize=(cols*3, rows*3))
plt.imshow(image)

#Binarize the y values,so that extend these algorithms to the multi-class classification case
y = label_binarize(y, classes=[0, 1, 2, 3])
n_classes = y.shape[1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.5, random_state = 0)

#svm_linear = OneVsRestClassifier(SVC(kernel= 'linear', probability = True, random_state=0))
svm = OneVsRestClassifier(SVC(kernel='linear', probability=True, random_state=42))
y_score = svm.fit(X_train, y_train).decision_function(X_test)

fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
colors = cycle(['yellow', 'cyan', 'magenta', 'darkorange'])
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color = color, lw = 2,
             label='ROC curve of class {0} (area = {1:0.2f})'
             ''.format(i, roc_auc[i]))
plt.plot([0, 1], [0, 1], 'k--', lw = 2)
plt.xlim([-0.05, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic for multi-class data')
plt.legend(loc = "lower right")
plt.show()

#y = label_binarize(y, classes=[0, 1, 2, 3])
#n_classes = y.shape[1]

#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.5, random_state = 0)

#svm_linear = OneVsRestClassifier(SVC(kernel= 'linear', probability = True, random_state=0))
rf = OneVsRestClassifier(RandomForestClassifier(n_estimators = 100, random_state = 0))
y_score = rf.fit(X_train, y_train).predict_proba(X_test)

fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
colors = cycle(['yellow', 'cyan', 'magenta', 'darkorange'])
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color = color, lw = 2,
             label='ROC curve of class {0} (area = {1:0.2f})'
             ''.format(i, roc_auc[i]))
plt.plot([0, 1], [0, 1], 'k--', lw = 2)
plt.xlim([-0.05, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic for multi-class data')
plt.legend(loc = "lower right")
plt.show()

